"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.neededStatTypeForRestrictionInput = exports.compareStatTypeToTransferRestrictionType = exports.compareTransferRestrictionToInput = exports.compareTransferRestrictionToStat = exports.compareStatsToInput = exports.assertTickerValid = exports.assertExpectedChainVersion = exports.assertExpectedSqVersion = exports.getExemptedIds = exports.defusePromise = exports.checkTxType = exports.getPortfolioIdsByName = exports.assembleBatchTransactions = exports.getCheckpointValue = exports.conditionsAreEqual = exports.hasSameElements = exports.toHumanReadable = exports.isModuleOrTagMatch = exports.optionize = exports.xor = exports.asFungibleAsset = exports.asAsset = exports.asTicker = exports.assertAddressValid = exports.assertIsPositive = exports.assertIsInteger = exports.createProcedureMethod = exports.calculateNextKey = exports.requestAtBlock = exports.requestMulti = exports.getApiAtBlock = exports.requestPaginated = exports.isAlphanumeric = exports.isPrintableAscii = exports.removePadding = exports.padString = exports.mergeReceipts = exports.sliceBatchReceipt = exports.segmentEventsByTransaction = exports.filterEventRecords = exports.createClaim = exports.getIdentity = exports.asDid = exports.asAccount = exports.asChildIdentity = exports.asIdentity = exports.getDid = exports.unserialize = exports.serialize = exports.delay = void 0;
exports.asNftId = exports.assembleAssetQuery = exports.getIdentityFromKeyRecord = exports.getExemptedBtreeSet = exports.getSecondaryAccountPermissions = exports.assertStatIsSet = void 0;
const util_1 = require("@polkadot/util");
const util_crypto_1 = require("@polkadot/util-crypto");
const bignumber_js_1 = __importDefault(require("bignumber.js"));
const json_stable_stringify_1 = __importDefault(require("json-stable-stringify"));
const lodash_1 = require("lodash");
const semver_1 = require("semver");
const websocket_1 = require("websocket");
const internal_1 = require("../internal");
const queries_1 = require("../middleware/queries");
const types_1 = require("../types");
const constants_1 = require("./constants");
const conversion_1 = require("./conversion");
const typeguards_1 = require("./typeguards");
__exportStar(require("../generated/utils"), exports);
/**
 * @hidden
 * Promisified version of a timeout
 *
 * @param amount - time to wait
 */
function delay(amount) {
    return __awaiter(this, void 0, void 0, function* () {
        return new Promise(resolve => {
            setTimeout(() => {
                resolve();
            }, amount);
        });
    });
}
exports.delay = delay;
/**
 * @hidden
 * Convert an entity type and its unique Identifiers to a base64 string
 */
function serialize(entityType, uniqueIdentifiers) {
    return Buffer.from(`${entityType}:${(0, json_stable_stringify_1.default)(uniqueIdentifiers)}`).toString('base64');
}
exports.serialize = serialize;
/**
 * @hidden
 * Convert a uuid string to an Identifier object
 */
function unserialize(id) {
    const unserialized = Buffer.from(id, 'base64').toString('utf8');
    const matched = unserialized.match(/^.*?:(.*)/);
    const errorMsg = 'Wrong ID format';
    if (!matched) {
        throw new Error(errorMsg);
    }
    const [, jsonString] = matched;
    try {
        return JSON.parse(jsonString);
    }
    catch (err) {
        throw new Error(errorMsg);
    }
}
exports.unserialize = unserialize;
/**
 * @hidden
 * Extract the DID from an Identity, or return the DID of the signing Identity if no Identity is passed
 */
function getDid(value, context) {
    return __awaiter(this, void 0, void 0, function* () {
        let did;
        if (value) {
            did = (0, conversion_1.signerToString)(value);
        }
        else {
            ({ did } = yield context.getSigningIdentity());
        }
        return did;
    });
}
exports.getDid = getDid;
/**
 * @hidden
 * Given a DID return the corresponding Identity, given an Identity return the Identity
 */
function asIdentity(value, context) {
    return typeof value === 'string' ? new internal_1.Identity({ did: value }, context) : value;
}
exports.asIdentity = asIdentity;
/**
 * @hidden
 * Given a DID return the corresponding ChildIdentity, given an ChildIdentity return the ChildIdentity
 */
function asChildIdentity(value, context) {
    return typeof value === 'string' ? new internal_1.ChildIdentity({ did: value }, context) : value;
}
exports.asChildIdentity = asChildIdentity;
/**
 * @hidden
 * Given an address return the corresponding Account, given an Account return the Account
 */
function asAccount(value, context) {
    return typeof value === 'string' ? new internal_1.Account({ address: value }, context) : value;
}
exports.asAccount = asAccount;
/**
 * @hidden
 * DID | Identity -> DID
 */
function asDid(value) {
    return typeof value === 'string' ? value : value.did;
}
exports.asDid = asDid;
/**
 * @hidden
 * Given an Identity, return the Identity, given a DID returns the corresponding Identity, if value is falsy, then return currentIdentity
 */
function getIdentity(value, context) {
    return __awaiter(this, void 0, void 0, function* () {
        if (!value) {
            return context.getSigningIdentity();
        }
        else {
            return asIdentity(value, context);
        }
    });
}
exports.getIdentity = getIdentity;
/**
 * @hidden
 */
function createClaim(claimType, jurisdiction, middlewareScope, cddId) {
    const type = claimType;
    const scope = (middlewareScope ? (0, conversion_1.middlewareScopeToScope)(middlewareScope) : {});
    switch (type) {
        case types_1.ClaimType.Jurisdiction: {
            return {
                type,
                // this assertion is necessary because CountryCode is not in the middleware types
                // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
                code: (0, util_1.stringUpperFirst)(jurisdiction.toLowerCase()),
                scope,
            };
        }
        case types_1.ClaimType.CustomerDueDiligence: {
            return {
                type,
                id: cddId,
            };
        }
    }
    return { type, scope };
}
exports.createClaim = createClaim;
/**
 * @hidden
 * Find every occurrence of a specific event inside a receipt
 *
 * @param skipError - optional. If true, no error will be thrown if the event is not found,
 *   and the function will return an empty array
 */
function filterEventRecords(receipt, mod, eventName, skipError) {
    const eventRecords = receipt.filterRecords(mod, eventName);
    if (!eventRecords.length && !skipError) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.UnexpectedError,
            message: `Event "${mod}.${String(eventName)}" wasn't fired even though the corresponding transaction was completed. Please report this to the Polymesh team`,
        });
    }
    return eventRecords.map(eventRecord => eventRecord.event);
}
exports.filterEventRecords = filterEventRecords;
/**
 * Return a clone of a transaction receipt with the passed events
 */
function cloneReceipt(receipt, events) {
    const { filterRecords, findRecord, toHuman } = receipt;
    const clone = Object.assign(Object.assign({}, receipt), { events });
    clone.filterRecords = filterRecords;
    clone.findRecord = findRecord;
    clone.toHuman = toHuman;
    return clone;
}
/**
 * @hidden
 *
 *   Segment a batch transaction receipt's events into arrays, each representing a specific extrinsic's
 *   associated events. This is useful for scenarios where we need to isolate and process events
 *   for individual extrinsics in a batch.
 *
 *   In a batch transaction receipt, events corresponding to multiple extrinsics are listed sequentially.
 *   This function identifies boundaries between these event sequences, typically demarcated by
 *   events like 'utility.ItemCompleted', to segment events into individual arrays.
 *
 *   A key use case is when we want to slice or filter events for a subset of the extrinsics. By
 *   segmenting events this way, it becomes simpler to apply operations or analyses to events
 *   corresponding to specific extrinsics in the batch.
 *
 * @param events - array of events from a batch transaction receipt
 *
 * @returns an array of arrays, where each inner array contains events specific to an extrinsic in the batch.
 *
 * @note this function does not mutate the input events
 */
function segmentEventsByTransaction(events) {
    const segments = [];
    let currentSegment = [];
    events.forEach(eventRecord => {
        if (eventRecord.event.method === 'ItemCompleted' && eventRecord.event.section === 'utility') {
            if (currentSegment.length) {
                segments.push(currentSegment);
                currentSegment = [];
            }
        }
        else {
            currentSegment.push(eventRecord);
        }
    });
    // If there are events left after processing, add them to a new segment
    if (currentSegment.length) {
        segments.push(currentSegment);
    }
    return segments;
}
exports.segmentEventsByTransaction = segmentEventsByTransaction;
/**
 * @hidden
 *
 * Return a clone of a batch transaction receipt that only contains events for a subset of the
 *   extrinsics in the batch. This is useful when a batch has several extrinsics that emit
 *   the same events and we want `filterEventRecords` to only search among the events emitted by
 *   some of them.
 *
 * A good example of this is when merging similar batches together. If we wish to preserve the return
 *   value of each batch, this is a good way of ensuring that the resolver function of a batch has
 *   access to the events that correspond only to the extrinsics in said batch
 *
 * @param from - index of the first transaction in the subset
 * @param to - end index of the subset (not included)
 *
 * @note this function does not mutate the original receipt
 */
function sliceBatchReceipt(receipt, from, to) {
    // checking if the batch was completed (will throw an error if not)
    filterEventRecords(receipt, 'utility', 'BatchCompleted');
    const { events } = receipt;
    const segmentedEvents = segmentEventsByTransaction(events);
    if (from < 0 || to > segmentedEvents.length) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.UnexpectedError,
            message: 'Transaction index range out of bounds. Please report this to the Polymesh team',
            data: {
                to,
                from,
            },
        });
    }
    const slicedEvents = segmentedEvents.slice(from, to).flat();
    return cloneReceipt(receipt, slicedEvents);
}
exports.sliceBatchReceipt = sliceBatchReceipt;
/**
 * Return a clone of the last receipt in the passes array, containing the accumulated events
 *   of all receipts
 */
function mergeReceipts(receipts, context) {
    const eventsPerTransaction = [];
    const allEvents = [];
    receipts.forEach(({ events }) => {
        eventsPerTransaction.push((0, conversion_1.bigNumberToU32)(new bignumber_js_1.default(events.length), context));
        allEvents.push(...events);
    });
    const lastReceipt = receipts[receipts.length - 1];
    /*
     * Here we simulate a `BatchCompleted` event with the amount of events of
     * each transaction. That way, if some psychopath user decides to merge a bunch of transactions
     * into a batch and then split it again, we won't lose track of which events correspond to which
     * transaction
     *
     * NOTE: this is a bit fragile since we might want to use more functionalities of the event object in the future,
     * but attempting to instantiate a real polkadot `GenericEvent` would be way more messy. It might come to that
     * in the future though. It's also worth considering that this is an extreme edge case, since (hopefully) no one
     * in their right mind would create a batch only to split it back up again
     */
    return cloneReceipt(lastReceipt, [
        ...allEvents,
        {
            event: {
                section: 'utility',
                method: 'BatchCompleted',
                data: [eventsPerTransaction],
            },
        },
    ]);
}
exports.mergeReceipts = mergeReceipts;
/**
 * @hidden
 */
function padString(value, length) {
    return (0, lodash_1.padEnd)(value, length, '\0');
}
exports.padString = padString;
/**
 * @hidden
 */
function removePadding(value) {
    // eslint-disable-next-line no-control-regex
    return value.replace(/\u0000/g, '');
}
exports.removePadding = removePadding;
/**
 * @hidden
 *
 * Return whether the string is fully printable ASCII
 */
function isPrintableAscii(value) {
    // eslint-disable-next-line no-control-regex
    return /^[\x00-\x7F]*$/.test(value);
}
exports.isPrintableAscii = isPrintableAscii;
/**
 * @hidden
 *
 * Return whether the string is fully alphanumeric
 */
function isAlphanumeric(value) {
    return /^[0-9a-zA-Z]*$/.test(value);
}
exports.isAlphanumeric = isAlphanumeric;
/**
 * @hidden
 *
 * Makes an entries request to the chain. If pagination options are supplied,
 *  the request will be paginated. Otherwise, all entries will be requested at once
 */
function requestPaginated(query, opts) {
    return __awaiter(this, void 0, void 0, function* () {
        const { arg, paginationOpts } = opts;
        let entries;
        let lastKey = null;
        const args = arg ? [arg] : [];
        if (paginationOpts) {
            const { size: pageSize, start: startKey } = paginationOpts;
            entries = yield query.entriesPaged({
                args,
                pageSize: pageSize.toNumber(),
                startKey,
            });
            if (pageSize.eq(entries.length)) {
                lastKey = entries[entries.length - 1][0].toHex();
            }
        }
        else {
            /*
             * NOTE @monitz87: this assertion is required because types
             *   are inconsistent in the polkadot repo
             */
            entries = yield query.entries(...args);
        }
        return {
            entries,
            lastKey,
        };
    });
}
exports.requestPaginated = requestPaginated;
/**
 * @hidden
 *
 * Gets Polymesh API instance at a particular block
 */
function getApiAtBlock(context, blockHash) {
    return __awaiter(this, void 0, void 0, function* () {
        const { polymeshApi } = context;
        const isArchiveNode = yield context.isCurrentNodeArchive();
        if (!isArchiveNode) {
            throw new internal_1.PolymeshError({
                code: types_1.ErrorCode.DataUnavailable,
                message: 'Cannot query previous blocks in a non-archive node',
            });
        }
        return polymeshApi.at(blockHash);
    });
}
exports.getApiAtBlock = getApiAtBlock;
// eslint-disable-next-line require-jsdoc
function requestMulti(context, queries, callback) {
    return __awaiter(this, void 0, void 0, function* () {
        const { polymeshApi: { queryMulti }, } = context;
        if (callback) {
            return queryMulti(queries, callback);
        }
        return queryMulti(queries);
    });
}
exports.requestMulti = requestMulti;
/**
 * @hidden
 *
 * Makes a request to the chain. If a block hash is supplied,
 *   the request will be made at that block. Otherwise, the most recent block will be queried
 */
function requestAtBlock(moduleName, queryName, opts, context) {
    return __awaiter(this, void 0, void 0, function* () {
        const { blockHash, args } = opts;
        let query;
        if (blockHash) {
            ({ query } = yield getApiAtBlock(context, blockHash));
        }
        else {
            ({ query } = context.polymeshApi);
        }
        const queryMethod = query[moduleName][queryName];
        return queryMethod(...args);
    });
}
exports.requestAtBlock = requestAtBlock;
/**
 * @hidden
 *
 * Calculates next page number for paginated GraphQL ResultSet.
 * Returns null if there is no next page.
 *
 * @param size - page size requested
 * @param start - start index requested
 * @param totalCount - total amount of elements returned by query
 *
 * @hidden
 *
 */
function calculateNextKey(totalCount, size, start) {
    const next = (start !== null && start !== void 0 ? start : new bignumber_js_1.default(0)).plus(size);
    return totalCount.gt(next) ? next : null;
}
exports.calculateNextKey = calculateNextKey;
// eslint-disable-next-line require-jsdoc
function createProcedureMethod(args, context) {
    const { getProcedureAndArgs, transformer, voidArgs, optionalArgs } = args;
    if (voidArgs) {
        const voidMethod = (opts = {}) => {
            const [proc, procArgs] = getProcedureAndArgs();
            return proc().prepare({ args: procArgs, transformer }, context, opts);
        };
        voidMethod.checkAuthorization = (opts = {}) => __awaiter(this, void 0, void 0, function* () {
            const [proc, procArgs] = getProcedureAndArgs();
            return proc().checkAuthorization(procArgs, context, opts);
        });
        return voidMethod;
    }
    if (optionalArgs) {
        const methodWithOptionalArgs = (methodArgs, opts = {}) => {
            const [proc, procArgs] = getProcedureAndArgs(methodArgs);
            return proc().prepare({ args: procArgs, transformer }, context, opts);
        };
        methodWithOptionalArgs.checkAuthorization = (methodArgs, opts = {}) => __awaiter(this, void 0, void 0, function* () {
            const [proc, procArgs] = getProcedureAndArgs(methodArgs);
            return proc().checkAuthorization(procArgs, context, opts);
        });
        return methodWithOptionalArgs;
    }
    const method = (methodArgs, opts = {}) => {
        const [proc, procArgs] = getProcedureAndArgs(methodArgs);
        return proc().prepare({ args: procArgs, transformer }, context, opts);
    };
    method.checkAuthorization = (methodArgs, opts = {}) => __awaiter(this, void 0, void 0, function* () {
        const [proc, procArgs] = getProcedureAndArgs(methodArgs);
        return proc().checkAuthorization(procArgs, context, opts);
    });
    return method;
}
exports.createProcedureMethod = createProcedureMethod;
/**
 * @hidden
 */
function assertIsInteger(value) {
    if (!value.isInteger()) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.ValidationError,
            message: 'The number must be an integer',
        });
    }
}
exports.assertIsInteger = assertIsInteger;
/**
 * @hidden
 */
function assertIsPositive(value) {
    if (value.isNegative()) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.ValidationError,
            message: 'The number must be positive',
        });
    }
}
exports.assertIsPositive = assertIsPositive;
/**
 * @hidden
 */
function assertAddressValid(address, ss58Format) {
    let encodedAddress;
    try {
        encodedAddress = (0, util_crypto_1.encodeAddress)((0, util_crypto_1.decodeAddress)(address), ss58Format.toNumber());
    }
    catch (err) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.ValidationError,
            message: 'The supplied address is not a valid SS58 address',
        });
    }
    if (address !== encodedAddress) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.ValidationError,
            message: "The supplied address is not encoded with the chain's SS58 format",
            data: {
                ss58Format,
            },
        });
    }
}
exports.assertAddressValid = assertAddressValid;
/**
 * @hidden
 */
function asTicker(asset) {
    return typeof asset === 'string' ? asset : asset.ticker;
}
exports.asTicker = asTicker;
/**
 * @hidden
 */
function asAsset(asset, context) {
    return typeof asset === 'string' ? new internal_1.BaseAsset({ ticker: asset }, context) : asset;
}
exports.asAsset = asAsset;
/**
 * @hidden
 * Transforms asset or ticker into a `FungibleAsset` entity
 */
function asFungibleAsset(asset, context) {
    if (asset instanceof internal_1.FungibleAsset) {
        return asset;
    }
    const ticker = typeof asset === 'string' ? asset : asset.ticker;
    return new internal_1.FungibleAsset({ ticker }, context);
}
exports.asFungibleAsset = asFungibleAsset;
/**
 * @hidden
 */
function xor(a, b) {
    return a !== b;
}
exports.xor = xor;
/**
 * @hidden
 * Transform a conversion util into a version that returns null if the input is falsy
 */
function optionize(converter) {
    return (value, ...rest) => {
        const data = value !== null && value !== void 0 ? value : null;
        return data && converter(data, ...rest);
    };
}
exports.optionize = optionize;
/**
 * @hidden
 * Compare two tags/modules and return true if they are equal, or if one is the other one's module
 */
function isModuleOrTagMatch(a, b) {
    const aIsTag = a.includes('.');
    const bIsTag = b.includes('.');
    // a tag b module
    if (aIsTag && !bIsTag) {
        return a.split('.')[0] === b;
    }
    // a module b tag
    if (!aIsTag && bIsTag) {
        return a === b.split('.')[0];
    }
    // both tags or both modules
    return a === b;
}
exports.isModuleOrTagMatch = isModuleOrTagMatch;
/**
 * @hidden
 *
 * Recursively convert a value into a human readable (JSON compliant) version:
 *   - Entities are converted via their `.toHuman` method
 *   - Dates are converted to ISO strings
 *   - BigNumbers are converted to numerical strings
 */
function toHumanReadable(obj) {
    if ((0, typeguards_1.isEntity)(obj)) {
        return obj.toHuman();
    }
    if (obj instanceof bignumber_js_1.default) {
        return obj.toString();
    }
    if (obj instanceof Date) {
        return obj.toISOString();
    }
    if (Array.isArray(obj)) {
        return obj.map(toHumanReadable);
    }
    if (obj && typeof obj === 'object') {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        return (0, lodash_1.mapValues)(obj, val => toHumanReadable(val));
    }
    return obj;
}
exports.toHumanReadable = toHumanReadable;
/**
 * @hidden
 *
 * Return whether the two arrays have same elements.
 * It uses a `comparator` function to check if elements are equal.
 * If no comparator function is provided, it uses `isEqual` function of `lodash`
 */
function hasSameElements(first, second, comparator = lodash_1.isEqual) {
    return !(0, lodash_1.differenceWith)(first, second, comparator).length && first.length === second.length;
}
exports.hasSameElements = hasSameElements;
/**
 * @hidden
 *
 * Perform a deep comparison between two compliance conditions
 */
function conditionsAreEqual(a, b) {
    let equalClaims = false;
    const { type: aType, trustedClaimIssuers: aClaimIssuers = [] } = a;
    const { type: bType, trustedClaimIssuers: bClaimIssuers = [] } = b;
    if ((0, typeguards_1.isSingleClaimCondition)(a) && (0, typeguards_1.isSingleClaimCondition)(b)) {
        equalClaims = (0, lodash_1.isEqual)(a.claim, b.claim);
    }
    else if ((0, typeguards_1.isMultiClaimCondition)(a) && (0, typeguards_1.isMultiClaimCondition)(b)) {
        const { claims: aClaims } = a;
        const { claims: bClaims } = b;
        equalClaims = hasSameElements(aClaims, bClaims);
    }
    else if (aType === types_1.ConditionType.IsIdentity && bType === types_1.ConditionType.IsIdentity) {
        equalClaims = (0, conversion_1.signerToString)(a.identity) === (0, conversion_1.signerToString)(b.identity);
    }
    else if (aType === types_1.ConditionType.IsExternalAgent && bType === types_1.ConditionType.IsExternalAgent) {
        equalClaims = true;
    }
    const equalClaimIssuers = hasSameElements(aClaimIssuers, bClaimIssuers, ({ identity: aIdentity, trustedFor: aTrustedFor }, { identity: bIdentity, trustedFor: bTrustedFor }) => (0, conversion_1.signerToString)(aIdentity) === (0, conversion_1.signerToString)(bIdentity) &&
        hasSameElements(aTrustedFor || [], bTrustedFor || []));
    return equalClaims && equalClaimIssuers;
}
exports.conditionsAreEqual = conditionsAreEqual;
/**
 * @hidden
 *
 * Transforms `InputCACheckpoint` values to `Checkpoint | CheckpointSchedule | Date` for easier processing
 */
function getCheckpointValue(checkpoint, asset, context) {
    return __awaiter(this, void 0, void 0, function* () {
        if (checkpoint instanceof internal_1.Checkpoint ||
            checkpoint instanceof internal_1.CheckpointSchedule ||
            checkpoint instanceof Date) {
            return checkpoint;
        }
        const assetEntity = asFungibleAsset(asset, context);
        const { type, id } = checkpoint;
        if (type === types_1.CaCheckpointType.Existing) {
            return assetEntity.checkpoints.getOne({ id });
        }
        else {
            return (yield assetEntity.checkpoints.schedules.getOne({
                id,
            })).schedule;
        }
    });
}
exports.getCheckpointValue = getCheckpointValue;
/**
 * @hidden
 */
function mapArgs({ transaction, argsArray, }) {
    return argsArray.map(args => ({
        transaction,
        args,
    }));
}
/**
 * Assemble the `transactions` array that is expected in a `BatchTransactionSpec` from a set of parameter arrays with their
 *   respective transaction
 *
 * @note This method ensures type safety for batches with a variable amount of transactions
 */
function assembleBatchTransactions(txsAndArgs) {
    return (0, lodash_1.flatMap)(txsAndArgs, mapArgs);
}
exports.assembleBatchTransactions = assembleBatchTransactions;
/**
 * @hidden
 *
 * Returns portfolio numbers for a set of portfolio names
 */
function getPortfolioIdsByName(rawIdentityId, rawNames, context) {
    return __awaiter(this, void 0, void 0, function* () {
        const { polymeshApi: { query: { portfolio }, }, } = context;
        const rawPortfolioNumbers = yield portfolio.nameToNumber.multi(rawNames.map(name => [rawIdentityId, name]));
        return rawPortfolioNumbers.map(number => {
            const rawPortfolioId = number.unwrapOr(null);
            return optionize(conversion_1.u64ToBigNumber)(rawPortfolioId);
        });
    });
}
exports.getPortfolioIdsByName = getPortfolioIdsByName;
/**
 * @hidden
 *
 * Check if a transaction matches the type of its args. Returns the same value but stripped of the types. This function has no logic, it's strictly
 *   for type safety when returning a `BatchTransactionSpec` with a variable amount of transactions
 */
function checkTxType(tx) {
    return tx;
}
exports.checkTxType = checkTxType;
/**
 * @hidden
 *
 * Add an empty handler to a promise to avoid false positive unhandled promise errors. The original promise
 *   is returned, so rejections are still bubbled up and caught properly. This is an ugly hack and should be used
 *   sparingly and only if you KNOW that rejections will be handled properly down the line
 *
 * More info:
 *
 * - https://github.com/facebook/jest/issues/6028#issuecomment-567851031
 * - https://stackoverflow.com/questions/59060508/how-to-handle-an-unhandled-promise-rejection-asynchronously
 * - https://stackoverflow.com/questions/40920179/should-i-refrain-from-handling-promise-rejection-asynchronously/40921505#40921505
 */
function defusePromise(promise) {
    promise.catch(lodash_1.noop);
    return promise;
}
exports.defusePromise = defusePromise;
/**
 * @hidden
 *
 * Transform an array of Identities into exempted IDs for Transfer Managers.
 *
 * @note even though the signature for `addExemptedEntities` requires `ScopeId`s as parameters,
 *   it accepts and handles `PolymeshPrimitivesIdentityId` parameters as well. Nothing special has to be done typing-wise since they're both aliases
 *   for `U8aFixed`
 *
 * @throws
 *   - if there are duplicated Identities/ScopeIDs
 */
function getExemptedIds(identities, context) {
    return __awaiter(this, void 0, void 0, function* () {
        const exemptedIds = [];
        const identityEntities = identities.map(identity => asIdentity(identity, context));
        exemptedIds.push(...identityEntities.map(identity => asDid(identity), context));
        const hasDuplicates = (0, lodash_1.uniq)(exemptedIds).length !== exemptedIds.length;
        if (hasDuplicates) {
            throw new internal_1.PolymeshError({
                code: types_1.ErrorCode.ValidationError,
                message: 'One or more of the passed exempted Identities are repeated or have the same Scope ID',
            });
        }
        return exemptedIds;
    });
}
exports.getExemptedIds = getExemptedIds;
/**
 * @hidden
 *
 * @returns true if the node version is within the accepted range
 */
function handleNodeVersionResponse(data, reject) {
    const { result: version } = data;
    const lowMajor = (0, semver_1.major)(constants_1.SUPPORTED_NODE_SEMVER).toString();
    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
    const high = (0, semver_1.coerce)(constants_1.SUPPORTED_NODE_VERSION_RANGE.split('||')[1].trim()).version;
    const highMajor = (0, semver_1.major)(high).toString();
    if (!(0, semver_1.satisfies)(version, lowMajor) && !(0, semver_1.satisfies)(version, highMajor)) {
        const error = new internal_1.PolymeshError({
            code: types_1.ErrorCode.FatalError,
            message: 'Unsupported Polymesh RPC node version. Please upgrade the SDK',
            data: {
                rpcNodeVersion: version,
                supportedVersionRange: constants_1.SUPPORTED_NODE_VERSION_RANGE,
            },
        });
        reject(error);
        return false;
    }
    if (!(0, semver_1.satisfies)(version, constants_1.SUPPORTED_NODE_VERSION_RANGE)) {
        console.warn(`This version of the SDK supports Polymesh RPC node version ${constants_1.SUPPORTED_NODE_VERSION_RANGE}. The node is at version ${version}. Please upgrade the SDK`);
    }
    return true;
}
/**
 * @hidden
 *
 * Add a dot to a number every three digits from right to left
 */
function addDotSeparator(value) {
    let result = '';
    value
        .toString()
        .split('')
        .reverse()
        .forEach((char, index) => {
        if ((index + 1) % 3 === 1 && index !== 0) {
            result = `.${result}`;
        }
        result = `${char}${result}`;
    });
    return result;
}
/**
 * @hidden
 *
 * @returns true if the spec version is within the accepted range
 */
function handleSpecVersionResponse(data, reject) {
    const { result: { specVersion }, } = data;
    /*
     * the spec version number comes as a single number (e.g. 5000000). It should be parsed as xxx_yyy_zzz
     * where xxx is the major version, yyy is the minor version, and zzz is the patch version. So for example, 5001023
     * would be version 5.1.23
     */
    const specVersionAsSemver = addDotSeparator(specVersion)
        .split('.')
        // remove leading zeroes, for example 020 becomes 20, 000 becomes 0
        .map((ver) => ver.replace(/^0+(?!$)/g, ''))
        .join('.');
    const lowMajor = (0, semver_1.major)(constants_1.SUPPORTED_SPEC_SEMVER).toString();
    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
    const high = (0, semver_1.coerce)(constants_1.SUPPORTED_SPEC_VERSION_RANGE.split('||')[1].trim()).version;
    const highMajor = (0, semver_1.major)(high).toString();
    if (!(0, semver_1.satisfies)(specVersionAsSemver, lowMajor) && !(0, semver_1.satisfies)(specVersionAsSemver, highMajor)) {
        const error = new internal_1.PolymeshError({
            code: types_1.ErrorCode.FatalError,
            message: 'Unsupported Polymesh chain spec version. Please upgrade the SDK',
            data: {
                specVersion: specVersionAsSemver,
                supportedVersionRange: constants_1.SUPPORTED_SPEC_VERSION_RANGE,
            },
        });
        reject(error);
        return false;
    }
    if (!(0, semver_1.satisfies)(specVersionAsSemver, constants_1.SUPPORTED_SPEC_VERSION_RANGE)) {
        console.warn(`This version of the SDK supports Polymesh chain spec version ${constants_1.SUPPORTED_SPEC_VERSION_RANGE}. The chain spec is at version ${specVersionAsSemver}. Please upgrade the SDK`);
    }
    return true;
}
/**
 * @hidden
 *
 * Checks SQ version compatibility with the SDK
 */
function assertExpectedSqVersion(context) {
    return __awaiter(this, void 0, void 0, function* () {
        const { data: { subqueryVersions: { nodes: [sqVersion], }, }, } = yield context.queryMiddleware((0, queries_1.latestSqVersionQuery)());
        if (!sqVersion || (0, semver_1.lt)(sqVersion.version, constants_1.MINIMUM_SQ_VERSION)) {
            console.warn(`This version of the SDK supports Polymesh Subquery version ${constants_1.MINIMUM_SQ_VERSION} or higher. Please upgrade the MiddlewareV2`);
        }
    });
}
exports.assertExpectedSqVersion = assertExpectedSqVersion;
/**
 * @hidden
 *
 * Checks chain version. This function uses a websocket as it's intended to be called during initialization
 * @param nodeUrl - URL for the chain node
 * @returns A promise that resolves if the version is in the expected range, otherwise it will reject
 */
function assertExpectedChainVersion(nodeUrl) {
    return new Promise((resolve, reject) => {
        const client = new websocket_1.w3cwebsocket(nodeUrl);
        client.onopen = () => {
            client.send(JSON.stringify(constants_1.SYSTEM_VERSION_RPC_CALL));
            client.send(JSON.stringify(constants_1.STATE_RUNTIME_VERSION_CALL));
        };
        let nodeVersionFetched;
        let specVersionFetched;
        client.onmessage = (msg) => {
            const data = JSON.parse(msg.data.toString());
            const { id } = data;
            if (id === constants_1.SYSTEM_VERSION_RPC_CALL.id) {
                nodeVersionFetched = handleNodeVersionResponse(data, reject);
            }
            else {
                specVersionFetched = handleSpecVersionResponse(data, reject);
            }
            if (nodeVersionFetched && specVersionFetched) {
                client.close();
                resolve();
            }
        };
        client.onerror = (error) => {
            client.close();
            const err = new internal_1.PolymeshError({
                code: types_1.ErrorCode.FatalError,
                message: `Could not connect to the Polymesh node at ${nodeUrl}`,
                data: { error },
            });
            reject(err);
        };
    });
}
exports.assertExpectedChainVersion = assertExpectedChainVersion;
/**
 * @hidden
 *
 * Validates a ticker value
 */
function assertTickerValid(ticker) {
    if (!ticker.length || ticker.length > constants_1.MAX_TICKER_LENGTH) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.ValidationError,
            message: `Ticker length must be between 1 and ${constants_1.MAX_TICKER_LENGTH} characters`,
        });
    }
    if (!isPrintableAscii(ticker)) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.ValidationError,
            message: 'Only printable ASCII is allowed as ticker name',
        });
    }
    if (ticker !== ticker.toUpperCase()) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.ValidationError,
            message: 'Ticker cannot contain lower case letters',
        });
    }
}
exports.assertTickerValid = assertTickerValid;
/**
 * @hidden
 * @returns true is the given stat is able to track the data for the given args
 */
function compareStatsToInput(rawStatType, args) {
    let claimIssuer;
    const { type } = args;
    if (type === types_1.StatType.ScopedCount || type === types_1.StatType.ScopedBalance) {
        claimIssuer = { issuer: args.issuer, claimType: args.claimType };
    }
    if (rawStatType.claimIssuer.isNone && !!claimIssuer) {
        return false;
    }
    if (rawStatType.claimIssuer.isSome) {
        if (!claimIssuer) {
            return false;
        }
        const { issuer, claimType } = claimIssuer;
        const [meshType, meshIssuer] = rawStatType.claimIssuer.unwrap();
        const issuerDid = (0, conversion_1.identityIdToString)(meshIssuer);
        const statType = (0, conversion_1.meshClaimTypeToClaimType)(meshType);
        if (issuerDid !== issuer.did) {
            return false;
        }
        if (statType !== claimType) {
            return false;
        }
    }
    const stat = (0, conversion_1.meshStatToStatType)(rawStatType);
    return stat === type;
}
exports.compareStatsToInput = compareStatsToInput;
/**
 * @hidden
 * @returns true if the given StatType is able to track the data for the given transfer condition
 */
function compareTransferRestrictionToStat(transferCondition, type, claimIssuer) {
    if ((type === types_1.StatType.Count && transferCondition.isMaxInvestorCount) ||
        (type === types_1.StatType.Balance && transferCondition.isMaxInvestorOwnership)) {
        return true;
    }
    if (!claimIssuer) {
        return false;
    }
    const { issuer: { did: issuerDid }, claimType, } = claimIssuer;
    let rawClaim, issuer;
    if (transferCondition.isClaimCount) {
        [rawClaim, issuer] = transferCondition.asClaimCount;
    }
    else if (transferCondition.isClaimOwnership) {
        [rawClaim, issuer] = transferCondition.asClaimOwnership;
    }
    if (rawClaim && issuer) {
        const restrictionIssuerDid = (0, conversion_1.identityIdToString)(issuer);
        const claim = (0, conversion_1.statsClaimToStatClaimInputType)(rawClaim);
        if (restrictionIssuerDid === issuerDid && claim.type === claimType) {
            return true;
        }
    }
    return false;
}
exports.compareTransferRestrictionToStat = compareTransferRestrictionToStat;
/**
 * @hidden
 */
function getClaimType(statClaim) {
    if (statClaim.isAccredited) {
        return types_1.ClaimType.Accredited;
    }
    else if (statClaim.isAffiliate) {
        return types_1.ClaimType.Affiliate;
    }
    else {
        return types_1.ClaimType.Jurisdiction;
    }
}
/**
 * @hidden
 */
function compareOptionalBigNumbers(a, b) {
    if (a === undefined && b === undefined) {
        return true;
    }
    if (a === undefined || b === undefined) {
        return false;
    }
    return a.eq(b);
}
/**
 * @hidden
 */
function compareTransferRestrictionToInput(rawRestriction, inputRestriction) {
    const { type, value } = inputRestriction;
    if (rawRestriction.isMaxInvestorCount && type === types_1.TransferRestrictionType.Count) {
        const currentCount = (0, conversion_1.u64ToBigNumber)(rawRestriction.asMaxInvestorCount);
        return currentCount.eq(value);
    }
    else if (rawRestriction.isMaxInvestorOwnership && type === types_1.TransferRestrictionType.Percentage) {
        const currentOwnership = (0, conversion_1.permillToBigNumber)(rawRestriction.asMaxInvestorOwnership);
        return currentOwnership.eq(value);
    }
    else if (rawRestriction.isClaimCount && type === types_1.TransferRestrictionType.ClaimCount) {
        const [statClaim, rawIssuerId, rawMin, maybeMax] = rawRestriction.asClaimCount;
        const issuerDid = (0, conversion_1.identityIdToString)(rawIssuerId);
        const min = (0, conversion_1.u64ToBigNumber)(rawMin);
        const max = maybeMax.isSome ? (0, conversion_1.u64ToBigNumber)(maybeMax.unwrap()) : undefined;
        const { min: valueMin, max: valueMax, claim: valueClaim, issuer: valueIssuer } = value;
        return (valueMin.eq(min) &&
            compareOptionalBigNumbers(max, valueMax) &&
            valueClaim.type === getClaimType(statClaim) &&
            issuerDid === valueIssuer.did);
    }
    else if (rawRestriction.isClaimOwnership && type === types_1.TransferRestrictionType.ClaimPercentage) {
        const { min: valueMin, max: valueMax, claim: valueClaim, issuer: valueIssuer } = value;
        const [statClaim, rawIssuerId, rawMin, rawMax] = rawRestriction.asClaimOwnership;
        const issuerDid = (0, conversion_1.identityIdToString)(rawIssuerId);
        const min = (0, conversion_1.permillToBigNumber)(rawMin);
        const max = (0, conversion_1.permillToBigNumber)(rawMax);
        return (valueMin.eq(min) &&
            valueMax.eq(max) &&
            valueClaim.type === getClaimType(statClaim) &&
            issuerDid === valueIssuer.did);
    }
    return false;
}
exports.compareTransferRestrictionToInput = compareTransferRestrictionToInput;
/**
 * @hidden
 */
function compareStatTypeToTransferRestrictionType(statType, transferRestrictionType) {
    const opType = (0, conversion_1.meshStatToStatType)(statType);
    if (opType === types_1.StatType.Count) {
        return transferRestrictionType === types_1.TransferRestrictionType.Count;
    }
    else if (opType === types_1.StatType.Balance) {
        return transferRestrictionType === types_1.TransferRestrictionType.Percentage;
    }
    else if (opType === types_1.StatType.ScopedCount) {
        return transferRestrictionType === types_1.TransferRestrictionType.ClaimCount;
    }
    else {
        return transferRestrictionType === types_1.TransferRestrictionType.ClaimPercentage;
    }
}
exports.compareStatTypeToTransferRestrictionType = compareStatTypeToTransferRestrictionType;
/**
 * @hidden
 * @param args.type TransferRestriction type that was given
 * @param args.claimIssuer optional Issuer and ClaimType for the scope of the Stat
 * @param context
 * @returns encoded StatType needed for the TransferRestriction to be enabled
 */
function neededStatTypeForRestrictionInput(args, context) {
    const { type, claimIssuer } = args;
    const rawOp = (0, conversion_1.transferRestrictionTypeToStatOpType)(type, context);
    const rawIssuer = claimIssuer ? (0, conversion_1.claimIssuerToMeshClaimIssuer)(claimIssuer, context) : undefined;
    return (0, conversion_1.statisticsOpTypeToStatType)({ op: rawOp, claimIssuer: rawIssuer }, context);
}
exports.neededStatTypeForRestrictionInput = neededStatTypeForRestrictionInput;
/**
 * @hidden
 * @throws if stat is not found in the given set
 */
function assertStatIsSet(currentStats, neededStat) {
    const needStat = ![...currentStats].find(s => s.eq(neededStat));
    if (needStat) {
        throw new internal_1.PolymeshError({
            code: types_1.ErrorCode.UnmetPrerequisite,
            message: 'The appropriate stat type for this restriction is not set. Try calling enableStat in the namespace first',
        });
    }
}
exports.assertStatIsSet = assertStatIsSet;
// eslint-disable-next-line require-jsdoc
function getSecondaryAccountPermissions(args, context, callback) {
    return __awaiter(this, void 0, void 0, function* () {
        const { polymeshApi: { query: { identity: identityQuery }, }, } = context;
        const { accounts, identity } = args;
        const assembleResult = (optKeyRecords) => {
            return optKeyRecords.reduce((result, optKeyRecord, index) => {
                const account = accounts[index];
                if (optKeyRecord.isNone) {
                    return result;
                }
                const record = optKeyRecord.unwrap();
                if (record.isSecondaryKey) {
                    const [rawIdentityId, rawPermissions] = record.asSecondaryKey;
                    if (identity && (0, conversion_1.identityIdToString)(rawIdentityId) !== identity.did) {
                        return result;
                    }
                    result.push({
                        account,
                        permissions: (0, conversion_1.meshPermissionsToPermissions)(rawPermissions, context),
                    });
                }
                return result;
            }, []);
        };
        const identityKeys = accounts.map(({ address }) => (0, conversion_1.stringToAccountId)(address, context));
        if (callback) {
            return identityQuery.keyRecords.multi(identityKeys, result => {
                return callback(assembleResult(result));
            });
        }
        const rawResults = yield identityQuery.keyRecords.multi(identityKeys);
        return assembleResult(rawResults);
    });
}
exports.getSecondaryAccountPermissions = getSecondaryAccountPermissions;
/**
 * @hidden
 */
function getExemptedBtreeSet(identities, ticker, context) {
    return __awaiter(this, void 0, void 0, function* () {
        const exemptedIds = yield getExemptedIds(identities, context);
        const mapped = exemptedIds.map(exemptedId => asIdentity(exemptedId, context));
        return (0, conversion_1.identitiesToBtreeSet)(mapped, context);
    });
}
exports.getExemptedBtreeSet = getExemptedBtreeSet;
/**
 * @hidden
 */
function getIdentityFromKeyRecord(keyRecord, context) {
    return __awaiter(this, void 0, void 0, function* () {
        const { polymeshApi: { query: { identity }, }, } = context;
        if (keyRecord.isPrimaryKey) {
            const did = (0, conversion_1.identityIdToString)(keyRecord.asPrimaryKey);
            return new internal_1.Identity({ did }, context);
        }
        else if (keyRecord.isSecondaryKey) {
            const did = (0, conversion_1.identityIdToString)(keyRecord.asSecondaryKey[0]);
            return new internal_1.Identity({ did }, context);
        }
        else {
            const multiSigAddress = keyRecord.asMultiSigSignerKey;
            const optMultiSigKeyRecord = yield identity.keyRecords(multiSigAddress);
            if (optMultiSigKeyRecord.isNone) {
                return null;
            }
            const multiSigKeyRecord = optMultiSigKeyRecord.unwrap();
            return getIdentityFromKeyRecord(multiSigKeyRecord, context);
        }
    });
}
exports.getIdentityFromKeyRecord = getIdentityFromKeyRecord;
/**
 * @hidden
 *
 * helper to construct proper type asset
 *
 * @note `assetDetails` and `tickers` must have the same offset
 */
function assembleAssetQuery(assetDetails, tickers, context) {
    return assetDetails.map((rawDetails, index) => {
        const ticker = tickers[index];
        const detail = rawDetails.unwrap();
        if (detail.assetType.isNonFungible) {
            return new internal_1.NftCollection({ ticker }, context);
        }
        else {
            return new internal_1.FungibleAsset({ ticker }, context);
        }
    });
}
exports.assembleAssetQuery = assembleAssetQuery;
/**
 * @hidden
 */
function asNftId(nft) {
    if (nft instanceof bignumber_js_1.default) {
        return nft;
    }
    else {
        return nft.id;
    }
}
exports.asNftId = asNftId;
//# sourceMappingURL=internal.js.map